{
  "hash": "19f978ae344341757421ac3757a4a3f0",
  "result": {
    "engine": "knitr",
    "markdown": "\n\n\n\n\n\n\n\n\n## Data Set-up: Tidying and Feature Selection\n\nBefore you can begin working with your data you must make sure that each row is a single observation, and each column is a single variable/predictor. This type of data set-up or \"wrangling\" is known as \"tidy data\". There are many readily available tutorials and textbooks that help you understand tidy data and how to clean and wranglde data to make it tidy. I recommend the [Tidyverse](https://r4ds.had.co.nz/tidy-data.html) chapter in the R data science textbook to start. Thankfully, the dataset from ManyDogs is already tidy so for this tutorial we can skip this step.\n\nAfter your data is tidy, the next step before is to complete feature selection. [*Feature selection*](#feature) is a fancy term for removing variables you aren't going to analyze and creating new ones by computing any necessary variables.\n\nMany of the changes you complete in this step are decided on through [domain knowledge](https://corporatefinanceinstitute.com/resources/data-science/domain-knowledge-data-science/): applying what you know about the field of research to make judgement calls on what is and isn't important to the model/data. The rest of our decisions depend on our specific research hypotheses. Anything in the data set that does not specifically pertain to our research hypotheses need to be eliminated to increase statistical power and to compute the model faster to save computing resources. Commonly deleted variables at this stage might include meta-data such as time of day when a survey was completed, or individual scale items when we have calculated the total scores. When domain knowledge doesn't suffice because you are working in a relatively new field, or past studies have conflicting information, you will want to let machine learning algorithms help choose what to keep and eliminate. See the [regularization](#regularization) section for more information.\n\nIn our ManyDogs example, our feature selection will include transforming all the levels of scales from words to values, add 0s to denote no household dogs other than the one in the study, computing average scores for each section of the CBARQ, and computing our binary outcome variables. We will then cut any remaining columns that will not be needed for analysis.\n\nReminder: The following code should be copied and pasted to get you to the needed dataset that we will be using in this tutorial.\n\n\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#The following code creates a new dataframe where all of the scales are changed from words to numbers so they can be used as discrete categorical data in the models we will create in this tutorial\nmanydogs_data_transformed <- manydogs_data |>\n  mutate(across(c(cbarq_train_1:cbarq_train_8), ~case_when(   #Change all scales from words to numbers\n    . == \"Never\" ~0,\n    . == \"Seldom\" ~1,\n    . == \"Sometimes\" ~2,\n    . == \"Usually\" ~3,\n    . == \"Always\" ~4\n  ))) |> \n  mutate(across(c(cbarq_aggression_1:cbarq_aggression_27), ~case_when(\n    . == \"No aggression\" ~ 0, \n    . == \"Mild aggression\" ~ 1,\n    . == \"Moderate aggression\" ~2,\n    . == \"High aggression\" ~3, \n    . == \"Serious aggression\" ~4\n  ))) |> \n  mutate(across(c(cbarq_fear_1:cbarq_fear_18), ~case_when(\n    . == \"No fear\" ~ 0, \n    . == \"Mild fear\" ~ 1,\n    . == \"Moderate fear\" ~2,\n    . == \"High fear\" ~3, \n    . == \"Extreme fear\" ~4\n  ))) |> \n  mutate(across(c(cbarq_separation_1:cbarq_separation_8), ~case_when(\n    . == \"Never\" ~0,\n    . == \"Seldom\" ~1,\n    . == \"Sometimes\" ~2,\n    . == \"Usually\" ~3,\n    . == \"Always\" ~4\n  ))) |> \n  mutate(across(c(cbarq_excitability_1:cbarq_excitability_6), ~case_when(\n    . == \"No excitability\" ~ 0, \n    . == \"Mild excitability\" ~ 1,\n    . == \"Moderate excitability\" ~2,\n    . == \"High excitability\" ~3, \n    . == \"Extreme excitability\" ~4\n  ))) |> \n  mutate(across(c(cbarq_attachment_1:cbarq_attachment_6), ~case_when(\n    . == \"Never\" ~0,\n    . == \"Seldom\" ~1,\n    . == \"Sometimes\" ~2,\n    . == \"Usually\" ~3,\n    . == \"Always\" ~4\n  ))) |> \n  mutate(across(c(cbarq_miscellaneous_1:cbarq_miscellaneous_27), ~case_when(\n    . == \"Never\" ~0,\n    . == \"Seldom\" ~1,\n    . == \"Sometimes\" ~2,\n    . == \"Usually\" ~3,\n    . == \"Always\" ~4\n  ))) |> \n  mutate(sex = case_when(sex == \"Female\" ~1, sex == \"Male\" ~2),\n         desexed = case_when(desexed == \"Yes\" ~1, desexed == \"No\" ~2),\n         purebred = case_when(purebred == \"Yes\"~1, purebred == \"No\" ~2),\n         gaze_follow = case_when(gaze_follow == \"Never\" ~ 1, \n                                 gaze_follow == \"Seldom\" ~2,\n                                 gaze_follow == \"Sometimes\"~3,\n                                 gaze_follow == \"Usually\" ~4,\n                                 gaze_follow == \"Always\" ~5),\n         num_household_dogs = ifelse(is.na(num_household_dogs), 0, num_household_dogs)) |>  #add 0s to indicate when no other dogs were in the household\n  mutate(across(c(cbarq_train_1:cbarq_train_8,cbarq_aggression_1:cbarq_miscellaneous_27), as.numeric))  #change character columns to numeric columns so R understand how to use them\n\n\n#Create a data frame that calculates composite scores for each subset of the scale and computes our three binary outcome variables\nmanydogs_feature_selection <- manydogs_data_transformed |> \n  mutate(training_score = rowMeans(select(manydogs_data_transformed,   #compute average scores of training\n                             starts_with(\"cbarq_train_\")), na.rm = TRUE),\n         aggression_score= rowMeans(select(manydogs_data_transformed,   #compute average scores of aggression\n                             starts_with(\"cbarq_aggression_\")), na.rm = TRUE),\n         fear_score= rowMeans(select(manydogs_data_transformed,    #compute average scores of fear\n                         starts_with(\"cbarq_fear_\")), na.rm = TRUE),\n         separation_score= rowMeans(select(manydogs_data_transformed,    ##compute average scores of separation issues\n                              starts_with(\"cbarq_separation_\")), na.rm = TRUE),\n         excitability_score = rowMeans(select(manydogs_data_transformed,    #compute average scores of excitability\n                                 starts_with(\"cbarq_excitability_\")), na.rm = TRUE),\n         attachment_score= rowMeans(select(manydogs_data_transformed,     #compute average scores of attachment\n                              starts_with(\"cbarq_attachment_\")), na.rm = TRUE),\n         miscellaneous_score= rowMeans(select(manydogs_data_transformed,    #compute average scores of miscellaneous behavior issues\n                                 starts_with(\"cbarq_miscellaneous_\")), na.rm = TRUE),\n         ostensive = rowMeans(select(manydogs_data_transformed, \n                                     starts_with(\"ostensive_\")), na.rm = TRUE), #create proportion correct on ostensive task\n         ostensive_binary = ifelse(ostensive <= 0.5, 0, 1), #create column that notes if a dog performed over or under chance at the ostensive task\n         nonostensive = rowMeans(select(manydogs_data_transformed,\n                                        starts_with(\"nonostensive_\")), na.rm = TRUE), #create proportion correct on nonostensive task\n         nonostensive_binary = ifelse(nonostensive <= 0.5, 0, 1),   #create column that notes if a dog performed over or under chance at the nonostensive task\n         os_best = ifelse(nonostensive > ostensive, 1, 0)) |>   #create column that notes if the dog was better at the nonostensive task\n  select(c(sex:purebred,gaze_follow,training_score:os_best))#grab the columns we will be using for the analysis in this tutorial\n```\n:::\n\n\n",
    "supporting": [
      "datacleaning_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}